from __future__ import annotations
from typing import List, Dict, Optional, Any, Tuple, TYPE_CHECKING
import struct

from sql.ast import ColumnDefinition, DataType, ColumnConstraint
from engine.constants import ROW_LENGTH_PREFIX_SIZE
from engine.catalog_page import CatalogPage
from engine.table_heap_page import TableHeapPage
from engine.data_page import DataPage
from engine.exceptions import TableAlreadyExistsError, PrimaryKeyViolationError, TableNotFoundError, \
    UniquenessViolationError
from storage.buffer_pool_manager import BufferPoolManager
from engine.transaction_manager import TransactionManager

if TYPE_CHECKING:
    from engine.index_manager import IndexManager


class StorageEngine:
    """
    å­˜å‚¨å¼•æ“ (é‡æ„å®Œå–„ç‰ˆ)ã€‚
    å°†æ‰€æœ‰æ•°æ®å’Œç´¢å¼•çš„ä¿®æ”¹æ“ä½œå°è£…èµ·æ¥ï¼Œä¿è¯åŸå­æ€§å’Œä¸€è‡´æ€§ã€‚
    """
    B_PLUS_TREE_KEY_SIZE = 16

    def __init__(self, buffer_pool_manager: BufferPoolManager):
        # [FIX] åœ¨ __init__ ä¸­æ‰çœŸæ­£å¯¼å…¥ï¼Œé¿å…æ¨¡å—åŠ è½½æ—¶çš„å¾ªç¯
        from engine.index_manager import IndexManager
        self.bpm = buffer_pool_manager
        self.index_managers: Dict[str, IndexManager] = {}
        self.indexes: Dict[str, BPlusTree] = {}
        self.txn_manager = TransactionManager(self)

        is_dirty = False
        catalog_page_raw = self.bpm.fetch_page(0)
        if catalog_page_raw is None:
            catalog_page_raw = self.bpm.new_page()
            if catalog_page_raw is None or catalog_page_raw.page_id != 0:
                raise RuntimeError("å…³é”®é”™è¯¯ï¼šç¼“å†²æ± æ— æ³•åˆ†é…æˆ–è·å– page_id=0 ä½œä¸ºç›®å½•é¡µã€‚")

        try:
            # æ£€æŸ¥é¡µé¢æ˜¯å¦å…¨ä¸º0ï¼Œæ¥åˆ¤æ–­æ˜¯å¦æ˜¯æ–°æ•°æ®åº“
            if any(b != 0 for b in catalog_page_raw.data):
                self.catalog_page = CatalogPage.deserialize(catalog_page_raw.data)
                is_dirty = False
            else:  # æ–°æ•°æ®åº“
                self.catalog_page = CatalogPage()
                catalog_page_raw.data = bytearray(self.catalog_page.serialize())
                is_dirty = True
        finally:
            self.bpm.unpin_page(0, is_dirty)

        self._load_all_indexes()

    def _load_all_indexes(self) -> None:
        """åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶ï¼Œä¸ºæ¯ä¸ªè¡¨åˆ›å»ºä¸€ä¸ª IndexManager å®ä¾‹æ¥åŠ è½½å…¶æ‰€æœ‰ç´¢å¼•ã€‚"""
        from engine.index_manager import IndexManager
        for table_name in self.catalog_page.tables.keys():
            self.index_managers[table_name] = IndexManager(table_name, self)

    def _prepare_key_for_b_tree(self, value: Any, col_type: DataType) -> bytes:
        """å°†Pythonå€¼è½¬æ¢ä¸ºB+æ ‘æœŸæœ›çš„ã€å›ºå®šé•¿åº¦ã€å¯æ¯”è¾ƒçš„å­—èŠ‚é”®ã€‚"""
        if value is None:
            raise ValueError("ç´¢å¼•é”®ä¸èƒ½ä¸º Noneã€‚")
        if col_type == DataType.INT:
            key_bytes = value.to_bytes(8, 'big', signed=True)
        elif col_type in (DataType.TEXT, DataType.STRING):
            key_bytes = str(value).encode('utf-8')
        else:
            raise NotImplementedError(f"ä¸æ”¯æŒçš„ä¸»é”®ç±»å‹ç”¨äºç´¢å¼•: {col_type.name}")

        if len(key_bytes) > self.B_PLUS_TREE_KEY_SIZE:
            print(f"è­¦å‘Š: ç´¢å¼•é”®å€¼ '{str(value)}' è¿‡é•¿ (>{self.B_PLUS_TREE_KEY_SIZE}å­—èŠ‚)ï¼Œå·²è¢«æˆªæ–­ã€‚")
            key_bytes = key_bytes[:self.B_PLUS_TREE_KEY_SIZE]

        return key_bytes.ljust(self.B_PLUS_TREE_KEY_SIZE, b'\x00')

    def _flush_catalog_page(self) -> None:
        """å°†ç›®å½•é¡µï¼ˆCatalogPageï¼‰çš„å†…å®¹åºåˆ—åŒ–å¹¶å¼ºåˆ¶å†™å›ç£ç›˜ã€‚"""
        catalog_page_raw = self.bpm.fetch_page(0)
        if catalog_page_raw:
            try:
                catalog_page_raw.data = bytearray(self.catalog_page.serialize())
                self.bpm.unpin_page(0, True)  # æ ‡è®°ä¸ºè„é¡µ
            except Exception as e:
                self.bpm.unpin_page(0, False)  # å‡ºé”™åˆ™ä¸æ ‡è®°
                raise e
        else:
            raise RuntimeError("åœ¨ç¼“å†²æ± ä¸­æ‰¾ä¸åˆ°ç›®å½•é¡µï¼Œæ— æ³•åˆ·æ–°ã€‚")

    def get_index_manager(self, table_name: str) -> Optional[IndexManager]:
        """è·å–æŒ‡å®šè¡¨çš„ç´¢å¼•ç®¡ç†å™¨ã€‚"""
        return self.index_managers.get(table_name)

    def create_table(self, table_name: str, columns: List[ColumnDefinition]) -> bool:
        """åˆ›å»ºæ–°è¡¨ï¼Œå¹¶è‡ªåŠ¨ä¸º PRIMARY KEY å’Œ UNIQUE çº¦æŸçš„åˆ—åˆ›å»ºç´¢å¼•ã€‚"""
        from engine.index_manager import IndexManager
        if table_name in self.catalog_page.tables:
            raise TableAlreadyExistsError(f"è¡¨ '{table_name}' å·²å­˜åœ¨ã€‚")

        table_heap_page = self.bpm.new_page()
        if not table_heap_page:
            raise MemoryError("ç¼“å†²æ± å·²æ»¡ï¼Œæ— æ³•ä¸ºè¡¨åˆ›å»ºæ–°çš„å †é¡µé¢ã€‚")

        try:
            schema_dict = {col.name: col for col in columns}
            self.catalog_page.add_table(table_name, table_heap_page.page_id, schema_dict)
            self._flush_catalog_page()

            # åˆå§‹åŒ–è¯¥è¡¨çš„ç´¢å¼•ç®¡ç†å™¨
            self.index_managers[table_name] = IndexManager(table_name, self)

            # ä¸ºä¸»é”®å’Œå”¯ä¸€çº¦æŸè‡ªåŠ¨åˆ›å»ºç´¢å¼•
            for col in columns:
                is_pk = any(c[0] == ColumnConstraint.PRIMARY_KEY for c in col.constraints)
                is_unique = any(c[0] == ColumnConstraint.UNIQUE for c in col.constraints)
                if is_pk or is_unique:
                    self.index_managers[table_name].create_index(col.name, is_unique=True)

            # åˆå§‹åŒ–ç©ºçš„å †é¡µé¢å†…å®¹
            empty_heap = TableHeapPage()
            table_heap_page.data = bytearray(empty_heap.serialize())
        finally:
            self.bpm.unpin_page(table_heap_page.page_id, True)

        return True

    def insert_row(self, table_name: str, row_data: bytes, row_dict: Dict[str, Any]) -> bool:
        """æ’å…¥ä¸€è¡Œæ•°æ®ï¼Œå¹¶å§”æ‰˜ IndexManager æ›´æ–°æ‰€æœ‰ç›¸å…³ç´¢å¼•ã€‚"""
    def insert_row(self, table_name: str, row_data: bytes, txn_id: Optional[int] = None) -> bool:
        """
        æ’å…¥ä¸€è¡Œæ•°æ®ã€‚
        - å¦‚æœ txn_id is Noneï¼šç«‹å³å†™å…¥ï¼ˆéäº‹åŠ¡æ¨¡å¼ï¼‰
        - å¦‚æœ txn_id ä¸ä¸º Noneï¼šå»¶è¿Ÿå†™å…¥ï¼ˆäº‹åŠ¡æ¨¡å¼ï¼Œç­‰åˆ° COMMIT æ—¶æ‰çœŸæ­£å†™ï¼‰
        """
        if txn_id is not None:
            # ğŸš©äº‹åŠ¡æ¨¡å¼ï¼šä¸ç«‹å³å†™å…¥ï¼Œå…ˆè®°å½•åœ¨ write set
            rid_placeholder = ("pending", len(self.txn_manager.transactions[txn_id]['writes']))
            # ç”¨ä¸€ä¸ªè™šæ‹Ÿ rid æ ‡è®°ï¼Œcommit æ—¶å†åˆ†é…çœŸæ­£çš„ RID
            self.txn_manager.add_write_set(
                txn_id,
                table_name,
                rid_placeholder,
                old_data=None,  # æ’å…¥æ“ä½œæ²¡æœ‰æ—§æ•°æ®
                new_data=row_data  # ç¼“å­˜æœªæäº¤çš„æ–°è¡Œ
            )
            print(f"[TXN {txn_id}] Insert scheduled for table '{table_name}', waiting for COMMIT.")
            return True

        # ğŸš©éäº‹åŠ¡æ¨¡å¼ï¼šç«‹å³æ‰§è¡ŒåŸæœ‰é€»è¾‘
        return self._do_insert_immediate(table_name, row_data)

    def _do_insert_immediate(self, table_name: str, row_data: bytes) -> bool:
        table_metadata = self.catalog_page.get_table_metadata(table_name)
        if not table_metadata:
            raise TableNotFoundError(table_name)

        heap_page_id = table_metadata['heap_root_page_id']
        heap_page_raw = self.bpm.fetch_page(heap_page_id)
        if not heap_page_raw:
            raise IOError(f"æ— æ³•ä¸ºè¡¨ '{table_name}' è·å–å †é¡µé¢ {heap_page_id}ã€‚")

        target_page_raw = None
        heap_page_is_dirty = False
        try:
            table_heap = TableHeapPage.deserialize(heap_page_raw.data)
            record_to_insert = (len(row_data) + ROW_LENGTH_PREFIX_SIZE).to_bytes(ROW_LENGTH_PREFIX_SIZE,
                                                                                 "little") + row_data

            # å¯»æ‰¾æœ‰è¶³å¤Ÿç©ºé—´çš„æ•°æ®é¡µ
            for page_id in reversed(table_heap.get_page_ids()):
                page_raw = self.bpm.fetch_page(page_id)
                if page_raw:
                    try:
                        data_page = DataPage(page_raw.page_id, page_raw.data)
                        if data_page.get_free_space() >= len(record_to_insert):
                            target_page_raw = page_raw
                            break
                    finally:
                        if target_page_raw is None or page_raw.page_id != target_page_raw.page_id:
                            self.bpm.unpin_page(page_id, False)

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„é¡µï¼Œåˆ™åˆ›å»ºæ–°é¡µ
            if not target_page_raw:
                target_page_raw = self.bpm.new_page()
                if not target_page_raw:
                    raise MemoryError("ç¼“å†²æ± å·²æ»¡ï¼Œæ— æ³•ä¸ºæ’å…¥åˆ›å»ºæ–°çš„æ•°æ®é¡µã€‚")
                table_heap.add_page_id(target_page_raw.page_id)
                heap_page_raw.data = bytearray(table_heap.serialize())
                heap_page_is_dirty = True

            # åœ¨ç›®æ ‡é¡µä¸­æ’å…¥è®°å½•
            target_data_page = DataPage(target_page_raw.page_id, target_page_raw.data)
            row_offset = target_data_page.insert_record(record_to_insert)
            target_page_raw.data = bytearray(target_data_page.get_data())

            rid = (target_page_raw.page_id, row_offset)

            # æ›´æ–°æ‰€æœ‰ç´¢å¼•
            index_manager = self.get_index_manager(table_name)
            if index_manager:
                try:
                    index_manager.insert_entry(row_dict, rid)
                except (PrimaryKeyViolationError, UniquenessViolationError) as e:
                    # å¦‚æœç´¢å¼•æ’å…¥å¤±è´¥ï¼ˆä¾‹å¦‚å”¯ä¸€æ€§å†²çªï¼‰ï¼Œåˆ™å›æ»šæ•°æ®æ’å…¥
                    self._delete_row_by_rid(table_name, rid)
                    raise e
            return True
        finally:
            self.bpm.unpin_page(heap_page_id, heap_page_is_dirty)
            if target_page_raw:
                self.bpm.unpin_page(target_page_raw.page_id, True)

    def delete_row(self, table_name: str, rid: Tuple[int, int]) -> bool:
        """åŸå­æ€§åœ°åˆ é™¤ä¸€è¡Œæ•°æ®åŠå…¶æ‰€æœ‰ç´¢å¼•æ¡ç›®ã€‚"""
        row_data_bytes = self.read_row(table_name, rid)
        if not row_data_bytes:
            return False

        row_dict = self._decode_row(table_name, row_data_bytes)

        # 1. å…ˆåˆ é™¤æ‰€æœ‰ç´¢å¼•æ¡ç›®
        index_manager = self.get_index_manager(table_name)
        if index_manager:
            index_manager.delete_entry(row_dict, rid)

        # 2. å†åˆ é™¤æ•°æ®é¡µä¸Šçš„è¡Œ
        return self._delete_row_by_rid(table_name, rid)

    def update_row(self, table_name: str, old_rid: Tuple[int, int], new_row_dict: Dict[str, Any]) -> bool:
        """
        ã€å¥å£®æ€§å¼ºåŒ–ã€‘åŸå­æ€§åœ°æ›´æ–°ä¸€è¡Œæ•°æ®åŠå…¶æ‰€æœ‰ç´¢å¼•æ¡ç›®ã€‚
        å¢åŠ äº†æ›´å®Œå–„çš„é”™è¯¯å¤„ç†å’Œå›æ»šå°è¯•ã€‚
        """
        old_row_data_bytes = self.read_row(table_name, old_rid)
        if not old_row_data_bytes:
            return False

        old_row_dict = self._decode_row(table_name, old_row_data_bytes)
        new_row_data_bytes = self._serialize_row(table_name, new_row_dict)
        index_manager = self.get_index_manager(table_name)

        # 1. æ›´æ–°å‰çš„é¢„æ£€æŸ¥
        if index_manager:
            try:
                index_manager.check_uniqueness_for_update(old_row_dict, new_row_dict, old_rid)
            except (PrimaryKeyViolationError, UniquenessViolationError) as e:
                raise e  # é¢„æ£€æŸ¥å¤±è´¥ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹

        # 2. æ›´æ–°æ•°æ®é¡µ
        new_rid = self._update_row_by_rid(table_name, old_rid, new_row_data_bytes)
        if new_rid is None:
            return False  # æ•°æ®é¡µæ›´æ–°å¤±è´¥

        # 3. æ›´æ–°ç´¢å¼•ï¼ˆå¦‚æœå¤±è´¥ï¼Œå°è¯•å›æ»šæ•°æ®é¡µçš„ä¿®æ”¹ï¼‰
        if index_manager:
            try:
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ å…¥æ–°çš„ridï¼Œå› ä¸ºè¡Œå¯èƒ½å·²ç»ç§»åŠ¨
                index_manager.delete_entry(old_row_dict, old_rid)
                index_manager.insert_entry(new_row_dict, new_rid)
            except Exception as e:
                # ã€å…³é”®ã€‘å°è¯•å›æ»šæ•°æ®é¡µçš„ä¿®æ”¹ä»¥ä¿æŒä¸€è‡´æ€§
                print(f"ä¸¥é‡é”™è¯¯ï¼šåœ¨æ›´æ–°ç´¢å¼•æ—¶å¤±è´¥ ({e})ã€‚æ­£åœ¨å°è¯•å›æ»šæ•°æ®é¡µçš„ä¿®æ”¹...")
                self._update_row_by_rid(table_name, new_rid, old_row_data_bytes)
                # æ³¨æ„ï¼šè¿™ä¸ªç®€å•çš„å›æ»šä¸èƒ½ä¿è¯100%æˆåŠŸï¼Œä½†èƒ½å¤„ç†å¤§å¤šæ•°æƒ…å†µ
                raise RuntimeError("ç´¢å¼•æ›´æ–°å¤±è´¥ï¼Œæ•°æ®ä¿®æ”¹å·²å›æ»šã€‚") from e

        return True

    def scan_table(self, table_name: str) -> List[Tuple[Tuple[int, int], bytes]]:
        """æ‰«æå…¨è¡¨ï¼Œè¿”å›æ‰€æœ‰è¡Œæ•°æ®åŠå…¶RIDã€‚"""
        table_metadata = self.catalog_page.get_table_metadata(table_name)
        if not table_metadata:
            raise TableNotFoundError(table_name)

        heap_page_id = table_metadata['heap_root_page_id']
        heap_page_raw = self.bpm.fetch_page(heap_page_id)
        if not heap_page_raw:
            raise IOError(f"æ— æ³•ä¸ºè¡¨ '{table_name}' è·å–å †é¡µé¢ {heap_page_id}ã€‚")

        results = []
        try:
            table_heap = TableHeapPage.deserialize(heap_page_raw.data)
            for data_page_id in table_heap.get_page_ids():
                page_raw = self.bpm.fetch_page(data_page_id)
                if not page_raw: continue
                try:
                    data_page = DataPage(page_raw.page_id, page_raw.data)
                    for offset, record in data_page.get_all_records():
                        results.append(((data_page_id, offset), record[ROW_LENGTH_PREFIX_SIZE:]))
                finally:
                    self.bpm.unpin_page(data_page_id, False)
        finally:
            self.bpm.unpin_page(heap_page_id, False)

        return results

    def read_row(self, table_name: str, rid: Tuple[int, int]) -> Optional[bytes]:
        """æ ¹æ®RIDï¼ˆè®°å½•IDï¼‰è¯»å–å•è¡Œæ•°æ®ã€‚"""
        page_id, offset = rid
        page = self.bpm.fetch_page(page_id)
        if not page: return None
        try:
            data_page = DataPage(page.page_id, page.data)
            record = data_page.get_record(offset)
            return record[ROW_LENGTH_PREFIX_SIZE:] if record else None
        finally:
            self.bpm.unpin_page(page_id, False)

    def _serialize_row(self, table_name: str, row_dict: Dict[str, Any]) -> bytes:
        """æ ¹æ® schema å°†å­—å…¸å½¢å¼çš„è¡Œæ•°æ®åºåˆ—åŒ–ä¸ºå­—èŠ‚æµã€‚"""
        metadata = self.catalog_page.get_table_metadata(table_name)
        if not metadata: raise TableNotFoundError(table_name)

        schema = metadata['schema']
        row_data = bytearray()
        if len(row_dict) != len(schema):
            raise ValueError(f"åˆ—æ•°ä¸åŒ¹é…ï¼šè¡¨ '{table_name}' éœ€è¦ {len(schema)} åˆ—ï¼Œä½†æä¾›äº† {len(row_dict)} åˆ—ã€‚")

        # ä¿è¯åºåˆ—åŒ–é¡ºåºä¸ schema å®šä¹‰çš„é¡ºåºä¸€è‡´
        for col_name in schema.keys():
            col_def = schema[col_name]
            val = row_dict[col_name]
            col_type = col_def.data_type
            if col_type == DataType.INT:
                row_data.extend(int(val).to_bytes(4, "little", signed=True))
            elif col_type in (DataType.TEXT, DataType.STRING):
                encoded_str = str(val).encode("utf-8")
                row_data.extend(len(encoded_str).to_bytes(4, "little"))
                row_data.extend(encoded_str)
            elif col_type == DataType.FLOAT:
                row_data.extend(struct.pack("<f", float(val)))
            else:
                raise NotImplementedError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {col_type}")
        return bytes(row_data)

    def _decode_row(self, table_name: str, row_data: bytes) -> Dict[str, Any]:
        """æ ¹æ® schema å°†å­—èŠ‚æµååºåˆ—åŒ–ä¸ºå­—å…¸å½¢å¼çš„è¡Œæ•°æ®ã€‚"""
        metadata = self.catalog_page.get_table_metadata(table_name)
        if not metadata: raise TableNotFoundError(table_name)

        schema = metadata['schema']
        row_dict = {}
        offset = 0
        for col_name, col_def in schema.items():
            value, new_offset = self._decode_value(row_data, offset, col_def.data_type)
            row_dict[col_name] = value
            offset = new_offset
        return row_dict

    # ã€æ–°å¢å‡½æ•°ã€‘ä¸º index_manager._populate_index æä¾›æ”¯æŒ
    def _decode_value_from_row(self, row_data: bytes, col_index: int, schema: Dict[str, Any]) -> Tuple[Any, int]:
        """ä»è¡Œå­—èŠ‚æµä¸­ä»…è§£ç æŒ‡å®šç´¢å¼•çš„åˆ—å€¼ï¼Œä»¥æé«˜ç´¢å¼•å¡«å……æ•ˆç‡ã€‚"""
        offset = 0
        current_col_idx = 0
        # å¿…é¡»ä¿è¯è¿­ä»£é¡ºåºä¸åºåˆ—åŒ–æ—¶ä¸€è‡´
        for col_def in schema.values():
            if current_col_idx == col_index:
                # æ‰¾åˆ°ç›®æ ‡åˆ—ï¼Œè§£ç å¹¶è¿”å›
                return self._decode_value(row_data, offset, col_def.data_type)
            # è·³è¿‡ä¸éœ€è¦çš„åˆ—ï¼Œåªæ›´æ–°åç§»é‡
            _, offset = self._decode_value(row_data, offset, col_def.data_type)
            current_col_idx += 1
        raise ValueError(f"åˆ—ç´¢å¼• {col_index} è¶Šç•Œã€‚")

    def _decode_value(self, row_data: bytes, offset: int, col_type: DataType) -> Tuple[Any, int]:
        """æ ¹æ®æ•°æ®ç±»å‹ä»å­—èŠ‚æµçš„æŒ‡å®šåç§»é‡è§£ç ä¸€ä¸ªå€¼ã€‚"""
        try:
            if col_type == DataType.INT:
                value = int.from_bytes(row_data[offset: offset + 4], "little", signed=True)
                offset += 4
            elif col_type in (DataType.TEXT, DataType.STRING):
                length = int.from_bytes(row_data[offset: offset + 4], "little")
                offset += 4
                value = row_data[offset: offset + length].decode("utf-8")
                offset += length
            elif col_type == DataType.FLOAT:
                value, = struct.unpack("<f", row_data[offset: offset + 4])
                offset += 4
            else:
                raise NotImplementedError(f"ä¸æ”¯æŒçš„è§£ç ç±»å‹: {col_type.name}")
            return value, offset
        except (struct.error, IndexError, UnicodeDecodeError) as e:
            raise ValueError(f"ä»åç§»é‡ {offset} è§£ç ç±»å‹ {col_type.name} å¤±è´¥: {e}")

    def _delete_row_by_rid(self, table_name: str, rid: Tuple[int, int]) -> bool:
        """ã€å†…éƒ¨æ–¹æ³•ã€‘æ ¹æ®RIDä»…åˆ é™¤æ•°æ®é¡µä¸Šçš„ä¸€è¡Œæ•°æ®ï¼ˆé€»è¾‘åˆ é™¤ï¼‰ã€‚"""
    def delete_row_by_rid(
            self,
            table_name: str,
            rid: Tuple[int, int],
            txn_id: Optional[int] = None
    ) -> bool:
        """
        æ ¹æ®RIDåˆ é™¤ä¸€è¡Œæ•°æ®ï¼ˆé€»è¾‘åˆ é™¤ï¼‰ã€‚
        - å¦‚æœ txn_id is None: ç«‹å³åˆ é™¤ (éäº‹åŠ¡æ¨¡å¼)ã€‚
        - å¦‚æœ txn_id ä¸ä¸º None: å»¶è¿Ÿåˆ é™¤ (äº‹åŠ¡æ¨¡å¼)ã€‚
        """
        page_id, offset = rid
        page = self.bpm.fetch_page(page_id)
        if not page:
            raise IOError(f"æ— æ³•ä¸ºåˆ é™¤æ“ä½œè·å–é¡µé¢ {page_id}ã€‚")

        try:
            data_page = DataPage(page.page_id, page.data)
            old_record = data_page.get_record(offset)
            old_row_data = old_record[ROW_LENGTH_PREFIX_SIZE:] if old_record else None

            if txn_id is not None:
                # ğŸš©äº‹åŠ¡æ¨¡å¼ï¼šåªè®°å½•ï¼Œä¸ç«‹å³åˆ é™¤
                self.txn_manager.add_write_set(
                    txn_id,
                    table_name,
                    rid,
                    old_data=old_row_data,  # å›æ»šæ—¶éœ€è¦é‡æ–°æ’å›
                    new_data=None
                )
                print(f"[TXN {txn_id}] Delete scheduled for table '{table_name}', rid={rid}, waiting for COMMIT.")
                return True

            # ğŸš©éäº‹åŠ¡æ¨¡å¼ï¼šç«‹å³åˆ é™¤
            return self._do_delete_immediate(table_name, rid)

        finally:
            self.bpm.unpin_page(page_id, False)

    def _do_delete_immediate(self, table_name: str, rid: Tuple[int, int]) -> bool:
        """çœŸæ­£æ‰§è¡Œåˆ é™¤ï¼Œç«‹å³ä¿®æ”¹ DataPageã€‚"""
        page_id, offset = rid
        page = self.bpm.fetch_page(page_id)
        if not page:
            raise IOError(f"æ— æ³•ä¸ºåˆ é™¤æ“ä½œè·å–é¡µé¢ {page_id}ã€‚")

        try:
            data_page = DataPage(page.page_id, page.data)
            deleted = data_page.delete_record(offset)
            if deleted:
                page.data = bytearray(data_page.get_data())
            return deleted
        finally:
            self.bpm.unpin_page(page_id, True)

    def _update_row_by_rid(self, table_name: str, rid: Tuple[int, int], new_row_data: bytes) -> Optional[
        Tuple[int, int]]:
        """ã€å†…éƒ¨æ–¹æ³•ã€‘æ ¹æ®RIDä»…æ›´æ–°æ•°æ®é¡µä¸Šçš„ä¸€è¡Œæ•°æ®ã€‚å¦‚æœè¡Œç§»åŠ¨ï¼Œä¼šè¿”å›æ–°çš„RIDã€‚"""
    def update_index_root(self, table_name: str, new_root_id: int) -> None:
        """æ›´æ–°å¹¶æŒä¹…åŒ–ä¸€ä¸ªè¡¨çš„ç´¢å¼•æ ¹é¡µé¢IDã€‚"""
        metadata = self.catalog_page.get_table_metadata(table_name)
        if not metadata:
            raise TableNotFoundError(table_name)
        metadata['index_root_page_id'] = new_root_id
        self._flush_catalog_page()

    def update_row_by_rid(
            self,
            table_name: str,
            rid: Tuple[int, int],
            new_row_data: bytes,
            txn_id: Optional[int] = None
    ) -> Optional[Tuple[int, int]]:
        """
        æ ¹æ®RIDæ›´æ–°ä¸€è¡Œæ•°æ®ã€‚
        - å¦‚æœ txn_id is None: ç«‹å³æ›´æ–° (éäº‹åŠ¡æ¨¡å¼)ã€‚
        - å¦‚æœ txn_id ä¸ä¸º None: å»¶è¿Ÿæ›´æ–° (äº‹åŠ¡æ¨¡å¼)ã€‚
        """
        page_id, old_offset = rid
        page = self.bpm.fetch_page(page_id)
        if not page:
            raise IOError(f"æ— æ³•ä¸ºæ›´æ–°æ“ä½œè·å–é¡µé¢ {page_id}ã€‚")

        try:
            data_page = DataPage(page.page_id, page.data)
            new_record = (len(new_row_data) + ROW_LENGTH_PREFIX_SIZE).to_bytes(ROW_LENGTH_PREFIX_SIZE,
                                                                               'little') + new_row_data
            new_offset, moved = data_page.update_record(old_offset, new_record)
            page.data = bytearray(data_page.get_data())
            return (page_id, new_offset)
        except (ValueError, IndexError):
            return None
        finally:
            self.bpm.unpin_page(page_id, True)
            old_record = data_page.get_record(old_offset)
            old_row_data = old_record[ROW_LENGTH_PREFIX_SIZE:] if old_record else None

            if txn_id is not None:
                # ğŸš©äº‹åŠ¡æ¨¡å¼ï¼šåªè®°å½•ï¼Œä¸ç«‹å³å†™å…¥
                self.txn_manager.add_write_set(
                    txn_id,
                    table_name,
                    rid,
                    old_data=old_row_data,  # ç”¨äºå›æ»š
                    new_data=new_row_data  # æäº¤æ—¶åº”ç”¨
                )
                print(f"[TXN {txn_id}] Update scheduled for table '{table_name}', rid={rid}, waiting for COMMIT.")
                return rid  # RID æš‚æ—¶ä¸å˜

            # ğŸš©éäº‹åŠ¡æ¨¡å¼ï¼šç«‹å³æ›´æ–°
            return self._do_update_immediate(table_name, rid, new_row_data)

        finally:
            self.bpm.unpin_page(page_id, False)

    def _do_update_immediate(
                    self,
                    table_name: str,
                    rid: Tuple[int, int],
                    new_row_data: bytes
            ) -> Optional[Tuple[int, int]]:
                """çœŸæ­£æ‰§è¡Œæ›´æ–°ï¼Œç«‹å³å†™ DataPageã€‚"""
                page_id, old_offset = rid
                page = self.bpm.fetch_page(page_id)
                if not page:
                    raise IOError(f"æ— æ³•ä¸ºæ›´æ–°æ“ä½œè·å–é¡µé¢ {page_id}ã€‚")

                try:
                    data_page = DataPage(page.page_id, page.data)
                    total_record_length = len(new_row_data) + ROW_LENGTH_PREFIX_SIZE
                    new_record = total_record_length.to_bytes(ROW_LENGTH_PREFIX_SIZE, 'little') + new_row_data

                    new_offset, moved = data_page.update_record(old_offset, new_record)
                    page.data = bytearray(data_page.get_data())
                    return (page_id, new_offset)
                except (ValueError, IndexError):
                    return None
                finally:
                    self.bpm.unpin_page(page_id, True)



