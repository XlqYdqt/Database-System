from typing import Dict, Any, List, Tuple, Optional
import struct

# [FIX] ç§»é™¤äº†æœªä½¿ç”¨çš„ FilterOperator å¯¼å…¥
# from engine.operators import FilterOperator
from engine.storage_engine import StorageEngine
# [FIX] å¯¼å…¥äº†é€»è¾‘è®¡åˆ’èŠ‚ç‚¹ Filterï¼Œç”¨äºæ­£ç¡®çš„ç±»å‹æ£€æŸ¥
from sql.ast import Operator, Expression, Column, Literal, BinaryExpression, DataType, ColumnConstraint, \
    ColumnDefinition
from engine.exceptions import TableNotFoundError, PrimaryKeyViolationError
from sql.planner import Filter


class UpdateOperator(Operator):
    """UPDATE æ“ä½œçš„æ‰§è¡Œç®—å­"""

    def __init__(self, table_name: str, child: Operator, updates: List[Tuple[str, Expression]],
                 storage_engine: StorageEngine, executor: Any, bplus_tree: Optional[Any] = None,
                 txn_id: Optional[int] = None):
        self.table_name = table_name
        self.child = child
        self.updates = updates
        self.storage_engine = storage_engine
        self.executor = executor
        self.bplus_tree = bplus_tree
        self.txn_id = txn_id

    def execute(self) -> List[Any]:
        """
        æ”¯æŒäº‹åŠ¡çš„ UPDATEï¼š
        - éäº‹åŠ¡æ¨¡å¼ (txn_id is None)ï¼šç«‹å³æ›´æ–°æ•°æ®å’Œç´¢å¼•
        - äº‹åŠ¡æ¨¡å¼ (txn_id is not None)ï¼šåªè®°å½•æ—¥å¿—ï¼Œå»¶è¿Ÿåˆ° COMMIT æ—¶åº”ç”¨
        """
        updated_count = 0

        try:
            schema = self.storage_engine.catalog_page.get_table_metadata(self.table_name)['schema']
        except (TypeError, KeyError):
            raise TableNotFoundError(self.table_name)

        rows_to_update: List[Tuple[Tuple[int, int], Dict[str, Any]]] = []

        # ============= 1. ä¼˜å…ˆç”¨ç´¢å¼•ï¼Œå¦åˆ™å…¨è¡¨æ‰«æ =============
        if self.bplus_tree and self._can_use_index():
            pk_value = self._extract_pk_value()
            if pk_value is not None:
                pk_col_def, _ = self.storage_engine._get_pk_info(schema)
                pk_bytes = self.storage_engine._prepare_key_for_b_tree(pk_value, pk_col_def.data_type)

                rid = self.bplus_tree.search(pk_bytes)
                if rid:
                    row_data_bytes = self.storage_engine.read_row(self.table_name, rid)
                    if row_data_bytes:
                        row_data_dict = self._deserialize_row_data(row_data_bytes, schema)
                        rows_to_update.append((rid, row_data_dict))
        else:
            rows_to_update = self.executor.execute([self.child])

        # ============= 2. é€è¡Œæ›´æ–° =============
        for original_rid, original_row_dict in rows_to_update:
            try:
                # æ„é€ æ–°è¡Œ
                new_row_dict = dict(original_row_dict)
                for col_name, expr in self.updates:
                    new_row_dict[col_name] = self._eval_expr(expr, original_row_dict)

                # ä¸»é”®ç›¸å…³
                pk_col_def, _ = self.storage_engine._get_pk_info(schema)
                pk_col_name = pk_col_def.name
                old_pk_value = original_row_dict[pk_col_name]
                new_pk_value = new_row_dict[pk_col_name]
                pk_changed = (old_pk_value != new_pk_value)

                # åºåˆ—åŒ–æ–°æ•°æ®
                new_row_data_bytes = self._serialize_row_data(new_row_dict, schema)

                # ğŸš© åˆ†äº‹åŠ¡æ¨¡å¼ & éäº‹åŠ¡æ¨¡å¼å¤„ç†
                if self.txn_id is not None:
                    # äº‹åŠ¡æ¨¡å¼ï¼šåªå†™å…¥æ—¥å¿—ï¼Œä¸å®é™…æ›´æ–°
                    old_row_data_bytes = self._serialize_row_data(original_row_dict, schema)
                    self.storage_engine.txn_manager.add_write_set(
                        self.txn_id,
                        self.table_name,
                        original_rid,
                        old_data=old_row_data_bytes,
                        new_data=new_row_data_bytes,
                    )
                else:
                    # éäº‹åŠ¡æ¨¡å¼ï¼šç«‹å³æ›´æ–°æ•°æ®
                    new_rid = self.storage_engine.update_row_by_rid(
                        self.table_name, original_rid, new_row_data_bytes
                    )
                    if new_rid is None:
                        print(f"è­¦å‘Š: æ›´æ–° RID {original_rid} å¤±è´¥ï¼Œå·²è·³è¿‡ã€‚")
                        continue

                    row_moved = (original_rid != new_rid)

                    # å¤„ç† B+ æ ‘ç´¢å¼•
                    if self.bplus_tree and (pk_changed or row_moved):
                        old_pk_bytes = self.storage_engine._prepare_key_for_b_tree(old_pk_value, pk_col_def.data_type)
                        new_pk_bytes = self.storage_engine._prepare_key_for_b_tree(new_pk_value, pk_col_def.data_type)

                        try:
                            self.bplus_tree.delete(old_pk_bytes)
                            insert_result = self.bplus_tree.insert(new_pk_bytes, new_rid)

                            if insert_result is None:
                                raise PrimaryKeyViolationError(new_pk_value)

                            if insert_result:  # root_changed
                                self.storage_engine.update_index_root(self.table_name, self.bplus_tree.root_page_id)

                        except Exception as e:
                            # å›æ»šç´¢å¼•å’Œè¡Œ
                            self.bplus_tree.insert(old_pk_bytes, original_rid)
                            original_row_data_bytes = self._serialize_row_data(original_row_dict, schema)
                            self.storage_engine.update_row_by_rid(self.table_name, new_rid, original_row_data_bytes)
                            raise e

                updated_count += 1
            except Exception as e:
                print(f"è­¦å‘Šï¼šæ›´æ–°è¡Œ {original_row_dict} æ—¶å‘ç”Ÿé”™è¯¯å¹¶å·²è·³è¿‡: {e}")
                continue

        return [updated_count]

    def _eval_expr(self, expr: Expression, row: Dict[str, Any]) -> Any:
        """é€’å½’åœ°å¯¹è¡¨è¾¾å¼æ±‚å€¼ã€‚"""
        if isinstance(expr, Literal): return expr.value
        if isinstance(expr, Column): return row.get(expr.name)
        if isinstance(expr, BinaryExpression):
            left_val = self._eval_expr(expr.left, row)
            right_val = self._eval_expr(expr.right, row)
            op_map = {"=": lambda a, b: a == b, ">": lambda a, b: a > b, "<": lambda a, b: a < b,
                      ">=": lambda a, b: a >= b, "<=": lambda a, b: a <= b, "!=": lambda a, b: a != b,
                      "<>": lambda a, b: a != b}
            op_val = getattr(expr, "op", getattr(expr, "operator", None)).value
            if op_val in op_map:
                return op_map[op_val](left_val, right_val)
            raise NotImplementedError(f"ä¸æ”¯æŒçš„äºŒå…ƒè¿ç®—ç¬¦: {op_val}")
        return expr

    def _can_use_index(self) -> bool:
        """åˆ¤æ–­ WHERE æ¡ä»¶æ˜¯å¦æ˜¯ `ä¸»é”® = å¸¸é‡` çš„å½¢å¼ï¼Œä»è€Œå†³å®šèƒ½å¦ä½¿ç”¨ç´¢å¼•ã€‚"""
        # [FIX] ä¿®å¤äº†ç±»å‹æ£€æŸ¥çš„ bugã€‚
        # ä¹‹å‰é”™è¯¯åœ°æ£€æŸ¥äº†ç‰©ç†ç®—å­ FilterOperatorï¼Œç°åœ¨æ­£ç¡®åœ°æ£€æŸ¥é€»è¾‘è®¡åˆ’èŠ‚ç‚¹ Filterã€‚
        if isinstance(self.child, Filter) and isinstance(self.child.condition, BinaryExpression):
            condition = self.child.condition
            try:
                schema = self.storage_engine.catalog_page.get_table_metadata(self.table_name)['schema']
                pk_col_name = self.storage_engine._get_pk_info(schema)[0].name
            except (TypeError, KeyError, ValueError):
                return False

            if (isinstance(condition.left, Column) and condition.left.name == pk_col_name and
                    isinstance(condition.right, Literal) and condition.op.value == '='):
                return True
        return False

    def _extract_pk_value(self) -> Any:
        """ä» WHERE æ¡ä»¶ä¸­æå–ä¸»é”®çš„å€¼ã€‚"""
        if self._can_use_index():
            return self.child.condition.right.value
        return None

    def _serialize_row_data(self, row_dict: Dict[str, Any], schema: Dict[str, ColumnDefinition]) -> bytes:
        """å°†å­—å…¸å½¢å¼çš„è¡Œæ•°æ®åºåˆ—åŒ–ä¸ºå­—èŠ‚æµã€‚"""
        row_data = bytearray()
        for col_def in schema.values():
            val = row_dict[col_def.name]
            if col_def.data_type == DataType.INT:
                row_data.extend(int(val).to_bytes(4, "little", signed=True))
            elif col_def.data_type in (DataType.TEXT, DataType.STRING):
                encoded = str(val).encode("utf-8")
                row_data.extend(len(encoded).to_bytes(4, "little"))
                row_data.extend(encoded)
            # --- [BUG FIX] ---
            # æ·»åŠ äº†å¯¹ FLOAT ç±»å‹çš„å¤„ç†ï¼Œä¹‹å‰ç¼ºå¤±å¯¼è‡´æ•°æ®åºåˆ—åŒ–ä¸å®Œæ•´ã€‚
            elif col_def.data_type == DataType.FLOAT:
                row_data.extend(struct.pack("<f", float(val)))
            # --- [END FIX] ---
        return bytes(row_data)

    def _deserialize_row_data(self, row_bytes: bytes, schema: Dict[str, ColumnDefinition]) -> Dict[str, Any]:
        """å°†å­—èŠ‚æµååºåˆ—åŒ–ä¸ºå­—å…¸å½¢å¼çš„è¡Œæ•°æ®ã€‚"""
        row_dict = {}
        offset = 0
        for col_def in schema.values():
            value, offset = self.storage_engine._decode_value(row_bytes, offset, col_def.data_type)
            row_dict[col_def.name] = value
        return row_dict
